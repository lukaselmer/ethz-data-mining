#!/usr/bin/env python2.7

import sys
import math
import numpy as np
from numpy import linalg as LA
#from sklearn.multiclass import OneVsRestClassifier
#from sklearn.svm import LinearSVC
#from sklearn.metrics import accuracy_score
#from sklearn import cross_validation

# This function has to either stay in this form or implement the
# feature mapping. For details refer to the handout pdf.


mean = np.array([ 0.00212536,  0.00323598,  0.00334741,  0.00174732,  0.00348527, 0.0036343 ,  0.00191515,  0.00218111,  0.00189414,  0.00345676, 0.00522611,  0.00448802,  0.00350482,  0.0030311 ,  0.00223899, 0.0017959 ,  0.00217003,  0.003804  ,  0.00254334,  0.00292594, 0.00645274,  0.00235215,  0.00436144,  0.00710972,  0.003686  , 0.0005966 ,  0.00301966,  0.00622906,  0.00182626,  0.00182724, 0.00329717,  0.00356091,  0.00246818,  0.00262105,  0.00356566, 0.00306296,  0.00212694,  0.00122471,  0.00211697,  0.00301619, 0.00162754,  0.01253491,  0.0025009 ,  0.00531617,  0.00266995, 0.00283006,  0.00397686,  0.0020605 ,  0.0030703 ,  0.00201766, 0.00403354,  0.00184067,  0.00316862,  0.00349592,  0.00414097, 0.003474  ,  0.00069861,  0.0013096 ,  0.00239266,  0.00395208, 0.0024268 ,  0.01225176,  0.00123664,  0.00266669,  0.00432014, 0.00065236,  0.00224353,  0.00080548,  0.00276062,  0.00118533, 0.00331108,  0.00336607,  0.00264712,  0.00096749,  0.00217621, 0.0026363 ,  0.00158128,  0.00304524,  0.00406601,  0.00275662, 0.0007914 ,  0.00261233,  0.00271745,  0.00277575,  0.00186329, 0.0023969 ,  0.00315315,  0.00289443,  0.00125863,  0.00219685, 0.00216235,  0.00226167,  0.00368494,  0.00281593,  0.000578  , 0.0030934 ,  0.00278462,  0.00130548,  0.00075274,  0.00357359, 0.00328313,  0.00234359,  0.00319046,  0.0038306 ,  0.00268314, 0.00097719,  0.00229539,  0.00136831,  0.00459601,  0.0038748 , 0.00044113,  0.00150722,  0.00246754,  0.00181257,  0.00281446, 0.00055259,  0.00416775,  0.00230592,  0.003582  ,  0.00194151, 0.00221837,  0.0021092 ,  0.00142144,  0.00604585,  0.00210917, 0.00230164,  0.00120513,  0.0029543 ,  0.0023046 ,  0.00085468, 0.00353689,  0.00227806,  0.00370309,  0.00273864,  0.00196237, 0.00206904,  0.00146357,  0.00018469,  0.00225274,  0.00352657, 0.00305713,  0.00238763,  0.00042998,  0.0030101 ,  0.00370833, 0.00240761,  0.00085715,  0.00111562,  0.00280072,  0.00137779, 0.0043529 ,  0.00319306,  0.00256304,  0.0023316 ,  0.00212424, 0.00290101,  0.00169565,  0.00281699,  0.00304787,  0.00316575, 0.00413756,  0.00058165,  0.00300637,  0.00028599,  0.00258115, 0.00198191,  0.00267296,  0.00018074,  0.00229846,  0.00191762, 0.00354951,  0.00304116,  0.00057767,  0.0011405 ,  0.0036294 , 0.00097022,  0.00187873,  0.00282934,  0.00402391,  0.00042891, 0.00087413,  0.00277922,  0.00215242,  0.00322924,  0.00126662, 0.00117505,  0.00245227,  0.00239826,  0.00361128,  0.00318832, 0.00532678,  0.00319156,  0.00300157,  0.00025666,  0.00229943, 0.00229807,  0.0041719 ,  0.00235066,  0.00479577,  0.00054912, 0.00093604,  0.00037214,  0.00083023,  0.00074274,  0.00281492, 0.00356604,  0.0056763 ,  0.00317055,  0.00141058,  0.00402161, 0.00273964,  0.00226665,  0.00131444,  0.00310347,  0.00148903, 0.0018932 ,  0.00238007,  0.00259854,  0.00186945,  0.00227102, 0.00418162,  0.00237885,  0.00223864,  0.00296711,  0.00078526, 0.00017063,  0.00072492,  0.00219495,  0.00235707,  0.0003474 , 0.00301344,  0.00409353,  0.00178444,  0.00451921,  0.00257377, 0.0021738 ,  0.00311017,  0.00137527,  0.00110618,  0.00356011, 0.00251556,  0.00429183,  0.00091361,  0.00151218,  0.00045477, 0.00206465,  0.00299401,  0.00059141,  0.00059235,  0.00555769, 0.00060291,  0.00240721,  0.00515399,  0.00321153,  0.00169015, 0.00241762,  0.00331553,  0.00180564,  0.00036335,  0.00230996, 0.00422967,  0.00331236,  0.00411302,  0.00089437,  0.00279886, 0.0020974 ,  0.00226069,  0.00215232,  0.00334075,  0.00256236, 0.00417578,  0.00240431,  0.00129805,  0.00386816,  0.00215664, 0.00325492,  0.00249186,  0.00391405,  0.00323212,  0.00354753, 0.00229521,  0.00208937,  0.00127088,  0.00295781,  0.00301805, 0.00313704,  0.00074384,  0.00229908,  0.00326307,  0.00282417, 0.00339275,  0.00214041,  0.00136305,  0.0025619 ,  0.00047618, 0.00142833,  0.00177502,  0.00042842,  0.00071333,  0.00304755, 0.00140338,  0.00247505,  0.00025771,  0.00430908,  0.00453807, 0.00470932,  0.00102237,  0.00274672,  0.00287423,  0.00250766, 0.00179227,  0.00282222,  0.00079524,  0.00142645,  0.00185798, 0.00184389,  0.00272046,  0.00314557,  0.00193267,  0.00175943, 0.00291154,  0.00051786,  0.00416061,  0.00133221,  0.0025179 , 0.00317253,  0.00159653,  0.0033122 ,  0.00325823,  0.001616  , 0.00042556,  0.00158678,  0.00139883,  0.0022141 ,  0.00295066, 0.00286429,  0.0012533 ,  0.00283503,  0.0001823 ,  0.00145585, 0.00259523,  0.0036271 ,  0.00284168,  0.00317833,  0.00092144, 0.0022639 ,  0.00311682,  0.00898942,  0.0019546 ,  0.00158946, 0.0030505 ,  0.00175393,  0.00253146,  0.00140447,  0.00050041, 0.00242248,  0.00165688,  0.00142386,  0.00259389,  0.00155265, 0.00194428,  0.00436356,  0.00248182,  0.0024745 ,  0.00325872, 0.00080892,  0.00047234,  0.00261369,  0.00300246,  0.00334687, 0.00301413,  0.00322806,  0.00257682,  0.00744426,  0.00263757, 0.00101945,  0.00185346,  0.00319897,  0.00255555,  0.00109804, 0.00164348,  0.00225396,  0.00062425,  0.00267991,  0.00114137, 0.00206982,  0.00062576,  0.00131843,  0.00305156,  0.00132452, 0.00173414,  0.00281548,  0.00460748,  0.00154452,  0.00266225, 0.00208893,  0.00324561,  0.00030079,  0.00116486,  0.00315777])
stdev = np.array([ 0.0019662 ,  0.00358637,  0.00350842,  0.00226225,  0.00439219, 0.00796661,  0.00357712,  0.00180532,  0.00262453,  0.0033471 , 0.0052014 ,  0.00380753,  0.00575737,  0.00260608,  0.00267297, 0.00260146,  0.00196098,  0.0037172 ,  0.00297025,  0.00260923, 0.0361273 ,  0.00222114,  0.00355037,  0.00852903,  0.00307512, 0.0020908 ,  0.00651014,  0.01028979,  0.00160833,  0.00182204, 0.00344497,  0.00736895,  0.00192456,  0.00211315,  0.00398435, 0.00294441,  0.00205787,  0.00214098,  0.00236506,  0.00504977, 0.00528482,  0.01397597,  0.00225324,  0.00606797,  0.00238514, 0.00225909,  0.00491472,  0.00187772,  0.00222408,  0.00165941, 0.00336069,  0.00218564,  0.00285131,  0.0041111 ,  0.00427183, 0.00399304,  0.00097788,  0.0020522 ,  0.00226158,  0.00286724, 0.0025106 ,  0.01460288,  0.00155887,  0.00320159,  0.00401971, 0.0011516 ,  0.0020148 ,  0.00196261,  0.0021309 ,  0.00148823, 0.00378017,  0.00348658,  0.00425919,  0.00134225,  0.00194059, 0.00260358,  0.00286553,  0.00306423,  0.00369534,  0.00246122, 0.00135166,  0.00332576,  0.00235   ,  0.00227407,  0.00161764, 0.0022196 ,  0.0035139 ,  0.00226587,  0.00150277,  0.00188227, 0.00200386,  0.00184031,  0.00355227,  0.00347167,  0.00115132, 0.00397397,  0.00222791,  0.00186027,  0.0020727 ,  0.00365927, 0.00288666,  0.00232391,  0.00275637,  0.00505802,  0.00213742, 0.00184464,  0.0020552 ,  0.00232236,  0.00646666,  0.00425995, 0.00124675,  0.00281901,  0.00196585,  0.00173503,  0.00261152, 0.00176984,  0.00310206,  0.00304849,  0.003996  ,  0.00276807, 0.00251787,  0.00213196,  0.00217666,  0.00997307,  0.00196995, 0.00180411,  0.00165206,  0.00369434,  0.00205622,  0.00114866, 0.00351798,  0.00211523,  0.0072829 ,  0.00214979,  0.00197069, 0.00189699,  0.00156339,  0.00103377,  0.00238883,  0.00379161, 0.00265343,  0.00289058,  0.00113665,  0.00236416,  0.00332597, 0.00227048,  0.00125937,  0.00202816,  0.00335457,  0.00180492, 0.00624744,  0.00358982,  0.00282187,  0.00230636,  0.00199916, 0.00226014,  0.00285517,  0.00260363,  0.00301461,  0.00459526, 0.00448624,  0.00209183,  0.00268071,  0.00090069,  0.00321627, 0.00206546,  0.00213981,  0.00105275,  0.00276969,  0.00212414, 0.0069508 ,  0.0024169 ,  0.00123   ,  0.00254072,  0.00393911, 0.00148401,  0.00204723,  0.00228144,  0.00449132,  0.00149097, 0.00174268,  0.00257225,  0.00320175,  0.00664419,  0.00189138, 0.0020448 ,  0.00280574,  0.00220309,  0.00297215,  0.00285228, 0.00536327,  0.00355922,  0.0025711 ,  0.00124935,  0.00201527, 0.00195973,  0.00607605,  0.00245182,  0.00597928,  0.00209872, 0.00145598,  0.0010389 ,  0.00260319,  0.00141827,  0.00220695, 0.00380162,  0.00693374,  0.0031467 ,  0.00140099,  0.00494411, 0.00257377,  0.00193931,  0.00227484,  0.00335309,  0.00158817, 0.00278453,  0.0028459 ,  0.00207249,  0.00224618,  0.00273257, 0.00304857,  0.00223643,  0.00239318,  0.00236711,  0.00111696, 0.0010058 ,  0.00206885,  0.00198781,  0.00210429,  0.00113712, 0.00229847,  0.00596205,  0.00179147,  0.00561444,  0.00213513, 0.00206347,  0.00231344,  0.00137523,  0.00197932,  0.00264595, 0.00267516,  0.00509817,  0.0024402 ,  0.00188696,  0.00113961, 0.00197233,  0.00365361,  0.00117616,  0.00131302,  0.01298396, 0.0011913 ,  0.00266607,  0.00519694,  0.00234513,  0.00243773, 0.00237652,  0.00685216,  0.00298989,  0.0010351 ,  0.00201191, 0.00544771,  0.00302676,  0.00465701,  0.00122883,  0.00459731, 0.00173858,  0.00204031,  0.00198842,  0.00319055,  0.00344188, 0.00454579,  0.00224685,  0.00153586,  0.00497766,  0.0024223 , 0.0026783 ,  0.00292938,  0.00488631,  0.00256491,  0.00377266, 0.00200616,  0.00282306,  0.00132664,  0.00494019,  0.0024599 , 0.00552509,  0.00216965,  0.00207395,  0.00351474,  0.00240341, 0.00344361,  0.00281899,  0.00205177,  0.00209401,  0.00124455, 0.00150425,  0.00159782,  0.00131002,  0.00107078,  0.00298575, 0.00134773,  0.00297753,  0.00129201,  0.00547464,  0.0056031 , 0.00400587,  0.0015023 ,  0.00299937,  0.00348804,  0.00238945, 0.00180438,  0.00283664,  0.00119193,  0.00136885,  0.00178396, 0.00208122,  0.00261019,  0.00268254,  0.00214596,  0.00201055, 0.00381193,  0.00123335,  0.00640843,  0.00221499,  0.00209865, 0.00400374,  0.00235229,  0.00292832,  0.00318154,  0.00217815, 0.00177626,  0.00156256,  0.00240472,  0.00190899,  0.0023404 , 0.00408978,  0.00194715,  0.00275155,  0.00101183,  0.00258561, 0.00205681,  0.00387566,  0.00286046,  0.00255025,  0.00150399, 0.00254396,  0.00247741,  0.02328686,  0.00165631,  0.0022278 , 0.00305526,  0.00186112,  0.00225358,  0.00223859,  0.00149986, 0.00229921,  0.00144856,  0.00265856,  0.00251296,  0.00448365, 0.00200931,  0.00551415,  0.00382038,  0.00408967,  0.00427716, 0.00120011,  0.00103054,  0.00326746,  0.00269401,  0.00292425, 0.00339665,  0.00332245,  0.00207661,  0.00610097,  0.00331902, 0.00121117,  0.00171915,  0.00271701,  0.00225461,  0.00161444, 0.00169935,  0.00188409,  0.00112991,  0.00231489,  0.00149696, 0.00204157,  0.0013547 ,  0.00262102,  0.00261974,  0.00159175, 0.00208   ,  0.00247807,  0.00679356,  0.00175094,  0.0021294 , 0.00180379,  0.00311996,  0.00094152,  0.00162778,  0.00244073])


def transform(x_original, make_np=True):

    x = []
    x.extend([1])


    x.extend( (x_original - mean) / stdev )

    def sqr(x):
        return x * x

    def sqr3(x):
        return x * x * x

    def e_pow(x):
        return math.exp(x)

    def me_pow(x):
        return math.exp(-x)


    #x.extend(map(sqr, x_original))
    #x.extend(map(e_pow, x_original))
    #x.extend(map(math.sqrt, x_original))
    #x.extend(map(sqr3, x_original))
    #x.extend(map(math.sin, x_original))
    #x.extend(map(me_pow, x_original))
    #x.extend(map(math.log, x_original))

    if make_np:
        return np.array(x)

    return x

if __name__ == "__main__":

    X = []
    Y = []
    k = 10

    #for line in open('./1-data/training.txt', 'r'):
    for line in sys.stdin:
        line = line.strip().split(' ')
        Y.append(int(line.pop(0)))
        X.append(transform(map(float, line)))

    X = np.array(X)
    Y = np.array(Y)



    w = np.mat(np.array([0.01] * np.shape(X)[1])).T

    T = 100000  #number of Trials
    lambdaValue = 0.5 #value of lambda - sorry lambda alone is a keyword... check that norm|w| <= 1/sqrt(lambda)

    for t in range(1, T):
        randomIndices = np.random.randint(0, X.shape[0], size=(k))
        X_t = X[randomIndices, :]
        Y_t = Y[randomIndices]

        predictorAsMatrix = np.mat(X_t)*w
        failedIndeces = Y_t*predictorAsMatrix.T[0].tolist()[0] < 1

        X_t_plus = np.mat(X_t[failedIndeces])
        Y_t_plus = np.mat(Y_t[failedIndeces]).T
        Y_t_plus = np.repeat(Y_t_plus, X.shape[1], 1)

        grad_t = (lambdaValue*w.T) -1/float(k)*np.sum(np.multiply(X_t_plus,Y_t_plus),0)

        eta_t = 1/(float(t)*lambdaValue)
        w_t_prime = w - (eta_t*grad_t).T

        w = min(1,(1/np.sqrt(lambdaValue))/LA.norm(w_t_prime))*w_t_prime

    s = ["%f" % x for x in w[:,0]]
    print 'key\t%s' % " ".join(s)